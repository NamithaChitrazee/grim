#+startup:fold
# ------------------------------------------------------------------------------
# grid submission workflow
# ------------------------
# *grim* works with projects. It is assumed that the information related to a project 
# is stored in a ./$project subdirectory of a current work area
#
# - a project includes generation of one or several dataset families and definitions 
#   of jobs to produce the datasets
#
# - 'dataset family' stands for several datasets related datasets, for example 
#   one dataset being an input for generation of another one
#   example 1: 'raw data' and 'reco' datasets containing the same events
#   example 2: stage 1 and stage 2 Mu2e beam tracing
#
#   in general, tracing the beam from the production to the stopping target 
#   may involve two, three or more stages
#
# datasets produced at different stages, together, comprise a dataset family
#
# for a given dataset family, configurations of all respective jobs are defined 
# in a $project/datasets/$family/init_project.py file.
# ------------------------------------------------------------------------------
* 0.0 [[file:init_project.org][format of init_project.py]]
* ------------------------------------------------------------------------------
* steps of the workflow
* ------------------------------------------------------------------------------
* 0.1) clone offline code from git, compile it
* 0.2) create _./.grid_config_ configuration file                            

  - it is created in the working (muse) directory for your project.
  - Below, $project stands for the project name
  - a .grid_config file could specify several projects 

   the template file:../scripts/.grid_config specifies just one. Quick explanation of the 
   configuration parameters:

- $project.base_release     : test release, the area where you build your code in _build_ subdirectory
- $project.code_tarball_dir : location of the code tarball , default: /mu2e/data/users/$USER/grid
                              build_tarball.py puts it there for job_submit.py to pick up
- $project.code_taball      : name of the code tarball to use
- $tmp_dir                  : area used to keep the project book-keeping information 
- $project.grid_output_dir  : the grid output arrives to ${$project.grid_output_dir}.$USER/workflow
- $project.log_dir          : area used to store the log files (away from /pnfs)

#+begin_src 
  source grim/scripts/create_project pbar2m   # project=pbar2m
#+end_src

  - this needs to be done just once. A template for the configuration file 
    can be found here: file:../scripts/.grid_config

  - edit the *.grid_config* file - everything there is self-explanatory for 
    those who ever submitted a grid job

  To add another project, do the same - edit the *.grid_config* file manually
  
  Note, that the code tarball tag has to be specified manually after the tarball 
  has been built (see next step).

* 0.3) build the code tarball                                                
  
   grim/scripts/build_tarball.py --project=$project

   the code tarball is automatically copied to /mu2e/data/users/$USER/grid/$project
   after the tarball is built, update .grid_config file to specify the tarball name there
   It is needed for grim/scripts/submit_job.py to find the code tarball 

   note: if /mu2e/data/users/$USER/grid/$project directory doesnt exist, just create it
   
   if the tarball is built under personal account and you're running as mu2epro, 
   copy tarball (as mu2epro), do teh following:

   grim/scripts/copy_user_tarball tarball

   Comment: using optimized libraries for grid submission saves a factor of x2-3
   in execution time.
	  
* 1.0) generate the FCL tarball                                              

   grim/scripts/gen_fcl.py .. parameters... (see gen_fcl help below)

   to generate the fcl tarfile for grid submission

   The fcl tarball is also copied to /pnfs/mu2e/scratch/$USER/fcl/$project 
   for jobsub to find it there

   again, if the directory doesn't exist, create it manually.
   note that 

* 1.1) test the tarballs locally                                             

- untar the code tarball in a new shell 
- source Code/setup.sh
- run your executable 

* 2.0) submit the grid job                                                   
   
#+begin_src                       
   grim/scripts/submit_job.py  (see help below)
#+end_src
   to submit a grid job

* 3.0) monitor status of submitted job(s) by running _grid_monitor.py_       

  grim/scripts/grid_monitor.py --project=$project

  When a job finishes, *grid_monitor* changes status of the job from 'running' to 'finished'

* 4.0) run _check_completed_job.py_ to identify failed segments :            

  grim/scripts/check_completed_job.py --project=<project> --grid_id=xxxxxxxx

  the script will check if all job segments have completed successfully and, 
  if some have failed, will automatically create an input for the recovery job. 
  To create an fcl tarball for the recovery job, run

  grim/scripts/gen_fcl.py --project=<project> --recover=<grid_id>
   
  where <grid_id> is a GRID ID of the initial job which needs to be recovered. 

* 4.1) if there were failed segments, try to recover, if needed              

  a) generate an FCL tarball for the recovery job 

  grim/scripts/gen_fcl.py --project=<project> --recover=<grid_id>

  b) submit a recovery job                  

  grim/scripts/submit_job.py --project=<project> --recover=<grid_id>

* 4.2) create input for the next stage                                       

  grim/scripts/list_pnfs_files.py --grid_id=<grid_id>

* 4.3) save log files of a successfully completed job:                       

       grim/scripts/copy_log_files.py --grid_id=<grid_id>

      do all that only after running grid_monitor.py - the scripts operate only on completed jobs, 
      which status files are available in tmp/$project/completed_jobs

* 5.0) proceed with the next stage
* ------------------------------------------------------------------------------
* pileup generation                                                          
- datasets describing additional inputs to generate the pileup are project-dependent.
  They are expected to be defined in the project configuration - 

                  $project/datasets/mixing/mixing_inputs.py 

* ------------------------------------------------------------------------------
* back to file:grim.org
* ------------------------------------------------------------------------------
